{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c42822d",
   "metadata": {},
   "source": [
    "# Requester's Guide \n",
    "\n",
    "The current release of Ravenverse provides a collection of easy to use libraries that allow requesters to build mathematical algorithms or models and compute these operations by distributing them across multiple Providers. This provides an increase in speed and efficiency when dealing with a large number of mathematical operations.\n",
    "\n",
    "Distributed Computing is the linking of various computing resources like PCs and smartphones to share and coordinate their processing power for a common computational requirement, such as the training of a large Machine Learning model. These resources or nodes communicate with a central server and in some cases with each other, such that each node receives some data and completes a subset of a task. These nodes can coordinate their computations to complete a large and complex computational requirement in a fast and efficient manner.\n",
    "\n",
    "This tutorial explains how to build a distributed graph that the requester can compile and execute via the participating Provider nodes present on the Ravenverse network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4abf4d",
   "metadata": {},
   "source": [
    "### Installing Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9398c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ravop\n",
    "!pip install ravdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61104f36",
   "metadata": {},
   "source": [
    "### Ravenverse Token\n",
    "\n",
    "The requester must connect to the Ravenverse using a unique token that they can generate by logging into Raven's Website (https://www.ravenverse.ai/) using their MetaMask wallet credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3c39d",
   "metadata": {},
   "source": [
    "### Setting Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bfe0490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKEN=YOUR_TOKEN\n",
      "env: RAVENVERSE_URL=http://server.ravenverse.ai\n",
      "env: RAVENVERSE_FTP_HOST=server.ravenverse.ai\n",
      "env: RAVENVERSE_FTP_URL=server.ravenverse.ai\n"
     ]
    }
   ],
   "source": [
    "%env TOKEN=YOUR_TOKEN\n",
    "%env RAVENVERSE_URL=http://server.ravenverse.ai\n",
    "%env RAVENVERSE_FTP_HOST=server.ravenverse.ai\n",
    "%env RAVENVERSE_FTP_URL=server.ravenverse.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5377ee1",
   "metadata": {},
   "source": [
    "### Generating a TorchScript Model File\n",
    "\n",
    "Let's start off by generating a ```.pt``` file for a regular CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c14ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding='same')\n",
    "        self.act_1 = nn.ReLU()\n",
    "        self.maxpool2d_1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.drp_1 = nn.Dropout(0.25)\n",
    "        self.bn_1 = nn.BatchNorm2d(16)\n",
    "        self.maxpool2d_2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding='same')\n",
    "        self.act_2 = nn.ReLU()\n",
    "        self.maxpool2d_3 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.drp_2 = nn.Dropout(0.25)\n",
    "        self.bn_2 = nn.BatchNorm2d(32)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_1 = nn.Linear(in_features=32,out_features=256)\n",
    "        self.act_3 = nn.ReLU()\n",
    "        self.drp_3 = nn.Dropout(0.4)\n",
    "        self.bn_3 = nn.BatchNorm1d(256)\n",
    "        self.dense_2 = nn.Linear(in_features=256, out_features=10)\n",
    "        self.act_4 = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv2d_1(x)\n",
    "        out = self.act_1(out)\n",
    "        out = self.maxpool2d_1(out)\n",
    "        out = self.drp_1(out)\n",
    "        out = self.bn_1(out)\n",
    "        out = self.maxpool2d_2(out)\n",
    "        out = self.conv2d_2(out)\n",
    "        out = self.act_2(out)\n",
    "        out = self.maxpool2d_3(out)\n",
    "        out = self.drp_2(out)\n",
    "        out = self.bn_2(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.dense_1(out)\n",
    "        out = self.act_3(out)\n",
    "        out = self.drp_3(out)\n",
    "        out = self.bn_3(out)\n",
    "        out = self.dense_2(out)\n",
    "        out = self.act_4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d838bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "model_script = torch.jit.script(model)\n",
    "\n",
    "model_script.save('test_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c4c93",
   "metadata": {},
   "source": [
    "Running the above cell will result in the creation of a ```test_model.pt``` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa422e02",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e7694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking version of RavDL...\n",
      "Current version of ravdl is 0.12\n",
      "Latest version of ravdl is 0.12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ravop as R\n",
    "import numpy as np\n",
    "from ravdl.v2 import Pytorch_Model\n",
    "from ravdl.v2.optimizers import Adam\n",
    "from ravdl.v2.utils.data_manipulation import batch_iterator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739e95c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 16:33:29,370 [MainThread  ] [DEBUG]  Checking version of Ravop...\n",
      "2023-06-12 16:33:29,581 [MainThread  ] [DEBUG]  Initializing...\n",
      "2023-06-12 16:33:29,582 [MainThread  ] [DEBUG]  Creating FTP developer credentials...\n",
      "2023-06-12 16:33:32,142 [MainThread  ] [DEBUG]  Error in speedtest:HTTP Error 403: Forbidden\n",
      "2023-06-12 16:33:32,144 [MainThread  ] [DEBUG]  FTP Upload Blocksize:8192\n",
      "2023-06-12 16:33:32,145 [MainThread  ] [DEBUG]  FTP User credentials:server.ravenverse.ai 6007485310 JX44JOJKUE\n",
      "2023-06-12 16:33:32,317 [MainThread  ] [DEBUG]  Initialized Successfully!\n",
      "2023-06-12 16:33:32,419 [MainThread  ] [DEBUG]  Your Current Graph ID:229\n",
      "2023-06-12 16:33:32,675 [MainThread  ] [DEBUG]  \n",
      "2023-06-12 16:33:32,677 [MainThread  ] [DEBUG]  {'message': 'Requester flushed'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ravop.core.Graph at 0x1692fab80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.initialize(ravenverse_token=os.environ.get(\"TOKEN\")) # Initialize with Requester token\n",
    "\n",
    "R.flush()             # Flush and discard existing graphs associated to this Requester (if any)\n",
    "\n",
    "R.Graph(name='cnn_model', algorithm='convolutional_neural_network', approach='distributed')     # create the distributed compute graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa881f8",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09dceefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(x, n_col=None):\n",
    "    if not n_col:\n",
    "        n_col = np.amax(x) + 1\n",
    "    one_hot = np.zeros((x.shape[0], n_col))\n",
    "    one_hot[np.arange(x.shape[0]), x] = 1\n",
    "    return one_hot\n",
    "\n",
    "data = datasets.load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "y = to_categorical(y.astype(\"int\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "# Reshape X to (n_samples, channels, height, width)\n",
    "X_train = X_train.reshape((-1, 1, 8, 8))\n",
    "X_test = X_test.reshape((-1, 1, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416bc8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path:  test_model.pt True\n",
      "Model exists\n",
      "Id self:  1\n"
     ]
    }
   ],
   "source": [
    "model_op = R.model('test_model.pt')\n",
    "optimizer = Adam()\n",
    "\n",
    "model = Pytorch_Model(model_op=model_op)\n",
    "model.initialize(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66d458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ca0be",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb02039",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    for X_batch, y_batch in batch_iterator(X_train, y_train, batch_size=256):\n",
    "        X_t = R.t(X_batch.astype(np.float32))\n",
    "        y_t = R.t(y_batch.astype(np.float32))\n",
    "\n",
    "        out = model._forward_pass(X_t)\n",
    "        loss = R.square_loss(y_t, out)\n",
    "\n",
    "        # Set step = True whenever optimizer step needs to be called after backprop (defaults to True).\n",
    "        model._backward_pass(loss, step = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8cbce9",
   "metadata": {},
   "source": [
    "### Saving the Model for Fetching it Post-Execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9629a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 16:33:36,246 [MainThread  ] [DEBUG]  \n",
      "2023-06-12 16:33:36,247 [MainThread  ] [DEBUG]  Persisting Op: my_net\n"
     ]
    }
   ],
   "source": [
    "model.save_model(name='my_net')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9793d05a",
   "metadata": {},
   "source": [
    "### Saving a Prediction output for Post-Execution\n",
    "\n",
    "Persisted a model forward pass output by the name \"output\". We will fetch this result later post-execution.\n",
    "Persisting Ops are a special category of Ops that stay in the ravenverse once the graph gets executed. The requester must explicitly mention which ops they want to save in their code. It is a good idea to write the code such that persisting ops contain the relevant results (in this case, variable - ```output```).\n",
    "\n",
    "***Note:*** Make sure that the ```name``` parameter for each persisting Op is unique within a graph so that later it can be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05eef466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 16:33:40,210 [MainThread  ] [DEBUG]  \n",
      "2023-06-12 16:33:40,212 [MainThread  ] [DEBUG]  Persisting Op: output\n"
     ]
    }
   ],
   "source": [
    "test_input = R.t(X_test.astype(np.float32))\n",
    "\n",
    "output = model._forward_pass(test_input, training=False)\n",
    "output.persist_op(name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4207a79",
   "metadata": {},
   "source": [
    "### Activating the Graph\n",
    "\n",
    "This step compiles all the Operations (Ops) in the Graph and shows the Cost of Execution (in Raven Tokens) and also the number of participant Provider nodes that will be required. This step makes the graph ready for execution. No more Ops can be added to the graph after this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d186cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 16:33:56,120 [MainThread  ] [DEBUG]  {'message': 'Ops Persisted Successfully!'}\n",
      "2023-06-12 16:34:01,260 [MainThread  ] [DEBUG]  \n",
      "\n",
      "2023-06-12 16:34:01,263 [MainThread  ] [DEBUG]  Graph Compiled Successfully. Ready to Execute!\n",
      "2023-06-12 16:34:01,264 [MainThread  ] [DEBUG]  Cost: 7455.57 RAVEN TOKENS\n",
      "2023-06-12 16:34:01,266 [MainThread  ] [DEBUG]  Max Participants: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Graph Compiled Successfully. Ready to Execute!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7d4f4",
   "metadata": {},
   "source": [
    "### Executing the Graph and Tracking Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "341742aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 16:34:05,872 [MainThread  ] [DEBUG]  Graph Execute Initiated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress |████████████████████████████████████████| 100/100 [100%] in 1:48.6 (0.92/s) \n",
      "\n",
      "Graph Computed Successfully!\n"
     ]
    }
   ],
   "source": [
    "R.execute()\n",
    "R.track_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de786db9",
   "metadata": {},
   "source": [
    "### Fetching the Persisted Op to Calculate Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78d4acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.741307371349096\n"
     ]
    }
   ],
   "source": [
    "prediction = R.fetch_persisting_op(op_name=\"output\")       # output was the name of the persisted op\n",
    "y_pred = np.argmax(prediction.detach().numpy(), axis=-1)\n",
    "y_test = np.argmax(y_test, axis=-1)\n",
    "\n",
    "accuracy = np.sum(y_pred == y_test, axis=0) / len(y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de63970",
   "metadata": {},
   "source": [
    "### Fetching the Trained Model to Calculate Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eed5c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 0 7 1 0 6 1 5 4 0 2 2 8 1 6 7 7 7 4 7 1 1 6 0 7 6 1 3 7 0 3 5 3 2 1 8\n",
      " 1 1 0 7 1 0 0 8 7 2 7 1 3 4 3 4 0 4 7 0 6 7 5 2 1 7 0 0 1 2 3 3 4 0 0 7 4\n",
      " 7 4 2 1 7 0 1 5 3 4 1 5 5 2 5 2 2 1 2 7 0 8 1 0 4 1 3 8 3 0 2 0 2 0 2 2 3\n",
      " 2 6 1 1 5 1 2 0 4 1 5 4 4 7 6 7 6 6 1 7 5 6 2 0 3 7 1 1 5 3 4 7 8 5 0 6 0\n",
      " 6 3 7 6 5 6 2 2 2 3 0 0 6 5 6 4 1 0 6 0 6 4 0 1 1 8 1 2 7 1 1 0 7 6 2 5 3\n",
      " 6 3 4 6 3 3 7 4 7 2 7 6 1 6 0 4 0 3 1 0 0 7 9 0 1 1 6 8 0 7 5 0 8 2 2 5 2\n",
      " 0 0 7 4 0 0 3 0 6 3 2 3 5 1 6 0 0 4 2 2 7 3 1 6 7 6 3 0 1 0 2 4 0 6 4 8 5\n",
      " 5 6 3 1 4 0 4 4 7 7 7 1 5 2 7 0 0 0 4 4 0 1 4 6 4 2 7 5 0 1 6 0 1 1 2 0 0\n",
      " 5 6 7 0 4 0 0 1 4 7 1 7 0 6 6 8 0 2 2 6 0 0 7 5 1 7 6 4 6 1 0 4 7 1 6 7 8\n",
      " 1 6 0 8 3 2 4 0 7 6 5 6 9 5 1 5 0 0 4 9 0 0 4 0 4 2 5 4 7 6 4 2 6 0 0 5 6\n",
      " 7 1 9 2 0 1 0 0 1 7 7 0 6 9 3 2 2 2 0 0 7 0 1 2 0 3 2 1 1 9 7 3 0 0 7 3 1\n",
      " 7 3 2 7 1 0 4 5 4 1 7 3 6 5 4 0 0 5 9 1 4 5 0 4 3 4 2 7 0 0 0 7 4 6 0 4 5\n",
      " 7 7 2 7 8 5 2 6 6 7 1 0 1 4 8 0 5 4 1 2 5 7 3 3 0 1 6 7 6 8 3 6 2 5 2 6 4\n",
      " 5 4 4 0 7 3 1 0 1 6 9 3 6 7 3 6 4 7 0 4 1 2 1 1 0 7 6 0 7 2 7 4 5 9 6 4 0\n",
      " 2 3 2 0 4 1 4 0 7 1 3 5 1 7 7 4 0 1 7 7 8 0 0 6 0 2 8 1 0 1 4 6 0 1 0 0 1\n",
      " 5 2 5 0 2 5 4 2 2 2 0 2 1 8 4 5 6 2 7 1 1 1 1 1 1 7 5 0 1 7 1 1 7 0 7 4 8\n",
      " 4 0 1 0 0 7 5 4 0 1 5 4 0 3 4 3 8 2 7 3 4 7 5 9 1 0 2 1 0 2 5 8 7 4 7 9 4\n",
      " 2 7 0 4 3 2 8 5 7 3 6 1 2 6 7 2 8 3 1 0 0 6 5 4 5 3 5 3 5 6 1 6 4 0 6 8 1\n",
      " 1 3 0 0 5 8 2 5 7 4 0 6 8 7 4 3 0 6 3 0 7 4 6 6 2 2 2 2 6 6 4 2 5 0 6 5 0\n",
      " 2 6 3 8 6 1 0 3 1 7 4 0 1 0 6 1]\n",
      "Accuracy of loaded model: 0.741307371349096\n"
     ]
    }
   ],
   "source": [
    "my_net = R.fetch_persisting_op(op_name=\"my_net\")\n",
    "my_net.eval()\n",
    "out = my_net(torch.tensor(X_test.astype(np.float32)))\n",
    "y_pred = np.argmax(out.detach().numpy(), axis=-1)\n",
    "print(y_pred)\n",
    "accuracy = np.sum(y_pred == y_test, axis=0) / len(y_test)\n",
    "\n",
    "print(\"Accuracy of loaded model:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd8b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
